# -*- coding: utf-8 -*-
"""SDM_ASSignment03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Zeq_5E83r5DXEQMg4vlSORZU-QFetta
"""

!pip install faiss-cpu --no-cache

import faiss
import numpy as np
import torch
import pandas as pd
import torchvision.transforms as transforms
from torchvision.datasets import MNIST
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])
#Here we have just loaded the dataset into the google colab notebook
train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)

train_images = train_dataset.data.numpy().astype(np.float32) / 255.0
train_labels = np.array(train_dataset.targets)

train_images, test_images, train_labels, test_labels = train_test_split(
    train_images, train_labels, test_size=0.2, random_state=42
)

train_images.shape

train_images = train_images.reshape(train_images.shape[0], -1) #Flattening the matrix for convinience in use later

train_images.shape

num_hash_functions = 10
hash_table_size = 100 #Here 99 can be the max size of the hash codes

hash_functions = np.random.randn(num_hash_functions, train_images.shape[1])
hash_table = [[] for _ in range(hash_table_size)]

# Hash training data into the hash table
for idx, image in enumerate(train_images):
    hashes = tuple(np.dot(hash_functions, image) > 0)
    #hashes stores boolean vector of length 10 for each image
    hash_code = hash(hashes) % hash_table_size
    #Hash codes are the final hashes generated which will be used for keeping them in separate buckets
    hash_table[hash_code].append(idx)
#This piece of code creates a hash table, each indice of which acts as a bucket in traditional sense.

def approximate_nearest_neighbor(query_image, num_candidates=10):
    query_hash = tuple(np.dot(hash_functions, query_image) > 0)
    query_hash_code = hash(query_hash) % hash_table_size
    #Generates hash code for the query image
    candidate_indices = hash_table[query_hash_code]
    #The candidate indices are the ones that get the same hash code values

    # Calculate distances to candidates and find the nearest neighbor
    distances = [np.linalg.norm(query_image - train_images[idx]) for idx in candidate_indices]
    #The candidate indices are here checked for their euclidean distance
    nearest_neighbor_idx = candidate_indices[np.argmin(distances)]
    nearest_neighbor_label = train_labels[nearest_neighbor_idx]

    return nearest_neighbor_label

def create_ivf_index(train_data, num_clusters):
    quantizer = faiss.IndexFlatL2(train_data.shape[1])
    index = faiss.IndexIVFFlat(quantizer, train_data.shape[1], num_clusters, faiss.METRIC_L2)
    index.train(train_data)
    index.add(train_data)
    return index

# Create HNSW index with L2 distance
def create_hnsw_index(train_data, num_neighbors, num_trees):
    index = faiss.IndexHNSWFlat(train_data.shape[1], num_neighbors, faiss.METRIC_L2)
    index.hnsw.efConstruction = num_trees
    index.add(train_data)
    return index

# Function to perform nearest neighbor search using FAISS index
def search_nearest_neighbors(index, query_data, k=1):
    distances, indices = index.search(query_data, k)
    return distances, indices

num_clusters = 100
num_neighbors = 10
num_trees = 100

def experiment_with_indices(train_data, num_clusters = 100, num_neighbors = 10, num_trees = 100):
    # Create IVF index and search for nearest neighbors
    ivf_index = create_ivf_index(train_data, num_clusters)
    ivf_distances, ivf_indices = search_nearest_neighbors(ivf_index, train_data, k=num_neighbors)

    # Create HNSW index and search for nearest neighbors
    hnsw_index = create_hnsw_index(train_data, num_neighbors, num_trees)
    hnsw_distances, hnsw_indices = search_nearest_neighbors(hnsw_index, train_data, k=num_neighbors)

    return ivf_distances, ivf_indices, hnsw_distances, hnsw_indices

ivf_distances, ivf_indices, hnsw_distances, hnsw_indices = experiment_with_indices(train_images)

df1 = pd.DataFrame()

df1["IVF_Indices"] = pd.Series(ivf_indices.reshape(-1))
df1["IVF_Distances"] = pd.Series(ivf_distances.reshape(-1))
df1["HNSW Indices"] = pd.Series(hnsw_indices.reshape(-1))
df1["HNSW_Distances"] = pd.Series(hnsw_distances.reshape(-1))

df1.head()

ivf_index = create_ivf_index(train_images, num_clusters)

hnsw_index = create_hnsw_index(train_images, num_neighbors, num_trees)

def calculate_recall_precision(true_labels, predicted_indices, k):
    total_queries = len(true_labels)
    true_positives = 0
    retrieved_items = 0

    for i in range(total_queries):
        true_label = true_labels[i]
        predicted_labels = [train_labels[index] for index in predicted_indices[i]]

        if true_label in predicted_labels[:k]:
            true_positives += 1

        retrieved_items += k


    recall = true_positives / total_queries
    precision = true_positives / retrieved_items

    return recall, precision

  #The function helps in calculating the recall and the precision values

def query_search_and_measure_recall_precision(images, labels, index, k=10):
    recalls, precisions = [], []
    for i in range(len(images)):
        query_image = images[i].reshape(-1)
        true_label = labels[i]

        # Perform query search using a loop
        distances = []
        indices = []
        for idx, train_image in enumerate(train_images):
            distance = np.linalg.norm(query_image - train_image)
            distances.append(distance)
            indices.append(idx)

        # Sort indices based on distances
        sorted_indices = sorted(range(len(distances)), key=lambda k: distances[k])
        sorted_indices = sorted_indices[:k]

        # Calculate recall and precision
        correct_predictions = sum(1 for idx in sorted_indices if idx < len(labels) and labels[idx] == true_label)
        recall = correct_predictions / k
        precision = correct_predictions / len(sorted_indices)

        recalls.append(recall)
        precisions.append(precision)

    return recalls, precisions

import random

# Set the size of the random subset
subset_size = 10  # You can adjust this based on your requirement

# Create a random subset from the test dataset
random_subset_indices = random.sample(range(len(test_images)), subset_size)
random_subset_images = [test_images[i] for i in random_subset_indices]
random_subset_labels = [test_labels[i] for i in random_subset_indices]

# Perform query search and measure recall and precision for IVF index
ivf_recalls, ivf_precisions = query_search_and_measure_recall_precision(random_subset_images, random_subset_labels, ivf_index)

# Perform query search and measure recall and precision for HNSW index
hnsw_recalls, hnsw_precisions = query_search_and_measure_recall_precision(random_subset_images, random_subset_labels, hnsw_index)

# Perform query search and measure recall and precision for LSH index
lsh_recalls, lsh_precisions = [], []
for query_vector, true_label in zip(random_subset_images, random_subset_labels):
    lsh_nearest_neighbor_label = approximate_nearest_neighbor(query_vector.reshape(-1))
    lsh_recall = int(lsh_nearest_neighbor_label == true_label)
    lsh_precision = lsh_recall
    lsh_recalls.append(lsh_recall)
    lsh_precisions.append(lsh_precision)

df = pd.DataFrame()
df["IVF_Recalls"] = pd.Series(ivf_recalls)
df["IVF_Precisions"] = pd.Series(ivf_precisions)
df["HNSW_Recalls"] = pd.Series(hnsw_recalls)
df["HNSW_Precisions"] = pd.Series(hnsw_precisions)
df["lsh_Recalls"] = pd.Series(lsh_recalls)
df["lsh_Precisions"] = pd.Series(lsh_precisions)

# Choose one query vector from the test dataset
query_index = 0  # Change this index to select a different query vector
query_vector = test_images[query_index].reshape(-1)  # Flatten the query image to shape (784,)

k = 10

# Perform query search for the selected query vector using IVF index
ivf_distances, ivf_indices = ivf_index.search(np.array([query_vector]), k)
ivf_nearest_neighbor_indices = ivf_indices[0]
ivf_nearest_neighbor_distances = ivf_distances[0]

# Perform query search for the selected query vector using HNSW index
hnsw_distances, hnsw_indices = hnsw_index.search(np.array([query_vector]), k)
hnsw_nearest_neighbor_indices = hnsw_indices[0]
hnsw_nearest_neighbor_distances = hnsw_distances[0]

# Perform query search for the selected query vector using LSH index
lsh_nearest_neighbor_label = approximate_nearest_neighbor(query_vector)

# Print the results
print("IVF Nearest Neighbor Indices:", ivf_nearest_neighbor_indices)
print("IVF Nearest Neighbor Distances:", ivf_nearest_neighbor_distances)
print("HNSW Nearest Neighbor Indices:", hnsw_nearest_neighbor_indices)
print("HNSW Nearest Neighbor Distances:", hnsw_nearest_neighbor_distances)
print("LSH Nearest Neighbor Label:", lsh_nearest_neighbor_label)

train_labels[0]

